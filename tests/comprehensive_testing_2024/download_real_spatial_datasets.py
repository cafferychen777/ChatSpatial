#!/usr/bin/env python3
"""
ä¸‹è½½çœŸå®çš„ç©ºé—´è½¬å½•ç»„æ•°æ®é›†ç”¨äºcomprehensive testing
åŒ…æ‹¬seqFISHã€MERFISHç­‰æŠ€æœ¯çš„é«˜è´¨é‡å·²å‘è¡¨æ•°æ®

æ•°æ®æ¥æºï¼š
- Squidpyå†…ç½®æ•°æ®é›†
- 10X Genomicså…¬å¼€æ•°æ®
- å·²å‘è¡¨è®ºæ–‡çš„è¡¥å……æ•°æ®
- GEO/SRAæ•°æ®åº“
"""

import os
import sys
import requests
import scanpy as sc
import pandas as pd
import numpy as np
from pathlib import Path
import gzip
import tarfile
from urllib.request import urlretrieve, urlopen
from urllib.error import URLError
import warnings
import json
from typing import Dict, List, Optional, Tuple
import time

warnings.filterwarnings('ignore')

# è®¾ç½®æ•°æ®ç›®å½•
BASE_DIR = Path(__file__).parent / 'datasets' / 'real_datasets'
BASE_DIR.mkdir(parents=True, exist_ok=True)

# æ•°æ®é›†å…ƒæ•°æ®è®°å½•
DATASETS_METADATA = {}

def log_dataset_info(dataset_name: str, **metadata):
    """è®°å½•æ•°æ®é›†ä¿¡æ¯"""
    DATASETS_METADATA[dataset_name] = {
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        **metadata
    }

def save_metadata():
    """ä¿å­˜æ‰€æœ‰æ•°æ®é›†çš„å…ƒæ•°æ®"""
    metadata_file = BASE_DIR / 'datasets_metadata.json'
    with open(metadata_file, 'w') as f:
        json.dump(DATASETS_METADATA, f, indent=2, ensure_ascii=False)
    print(f"æ•°æ®é›†å…ƒæ•°æ®ä¿å­˜è‡³: {metadata_file}")

def download_squidpy_datasets():
    """ä¸‹è½½squidpyå†…ç½®çš„æ ‡å‡†æ•°æ®é›†"""
    print("\n=== ä¸‹è½½Squidpyå†…ç½®æ•°æ®é›† ===")
    
    try:
        import squidpy as sq
        print(f"âœ“ Squidpyç‰ˆæœ¬: {sq.__version__}")
        
        datasets_to_download = [
            ('seqfish', 'seqFISH+ Mouse Embryo', 'Lohoff et al., Nature 2022'),
            ('merfish', 'MERFISH Hypothalamus', 'Moffitt et al., Science 2018'),
            ('mibitof', 'MIBIToF Breast Cancer', 'Keren et al., Cell 2018'),
            ('slideseqv2', 'Slide-seqV2 Mouse Hippocampus', 'Stickels et al., Nature Biotechnology 2021'),
            ('visium', '10X Visium Brain Section', '10X Genomics Dataset'),
            ('imc', 'IMC Breast Cancer', 'Jackson et al., Nature 2020'),
        ]
        
        for dataset_id, description, citation in datasets_to_download:
            try:
                print(f"  ä¸‹è½½ {dataset_id} ({description})...")
                
                # åŠ¨æ€è·å–æ•°æ®é›†
                dataset_func = getattr(sq.datasets, dataset_id, None)
                if dataset_func is None:
                    print(f"    âŒ {dataset_id} ä¸å¯ç”¨")
                    continue
                
                adata = dataset_func()
                output_file = BASE_DIR / f'squidpy_{dataset_id}.h5ad'
                adata.write(output_file)
                
                # è®°å½•å…ƒæ•°æ®
                log_dataset_info(f'squidpy_{dataset_id}', 
                    source='squidpy',
                    technology=dataset_id.upper(),
                    description=description,
                    citation=citation,
                    n_cells=adata.n_obs,
                    n_genes=adata.n_vars,
                    has_spatial='spatial' in adata.obsm,
                    file_path=str(output_file.relative_to(BASE_DIR.parent.parent)),
                    file_size_mb=round(output_file.stat().st_size / 1024 / 1024, 2)
                )
                
                print(f"    âœ“ å®Œæˆ: {adata.n_obs} cells, {adata.n_vars} genes")
                
            except Exception as e:
                print(f"    âŒ ä¸‹è½½ {dataset_id} å¤±è´¥: {e}")
        
    except ImportError:
        print("âŒ squidpyæœªå®‰è£…ï¼Œè·³è¿‡å†…ç½®æ•°æ®é›†ä¸‹è½½")
    except Exception as e:
        print(f"âŒ ä¸‹è½½squidpyæ•°æ®é›†æ—¶å‡ºé”™: {e}")

def download_10x_genomics_datasets():
    """ä¸‹è½½10X Genomics Visiumå…¬å¼€æ•°æ®é›†"""
    print("\n=== ä¸‹è½½10X Genomicså…¬å¼€æ•°æ®é›† ===")
    
    # 10X Genomics å…¬å¼€æ•°æ®é›†
    datasets = {
        'visium_human_brain': {
            'name': 'Human Brain Section (Anterior)',
            'matrix_url': 'https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Human_Brain_Section_2/V1_Human_Brain_Section_2_filtered_feature_bc_matrix.h5',
            'spatial_url': 'https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Human_Brain_Section_2/V1_Human_Brain_Section_2_spatial.tar.gz',
            'citation': '10X Genomics, Spatial Gene Expression Dataset',
        },
        'visium_mouse_brain': {
            'name': 'Mouse Brain Section (Sagittal-Anterior)',
            'matrix_url': 'https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Adult_Mouse_Brain/V1_Adult_Mouse_Brain_filtered_feature_bc_matrix.h5',
            'spatial_url': 'https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Adult_Mouse_Brain/V1_Adult_Mouse_Brain_spatial.tar.gz',
            'citation': '10X Genomics, Spatial Gene Expression Dataset',
        }
    }
    
    for dataset_id, info in datasets.items():
        try:
            print(f"  ä¸‹è½½ {dataset_id} ({info['name']})...")
            dataset_dir = BASE_DIR / dataset_id
            dataset_dir.mkdir(exist_ok=True)
            
            # ä¸‹è½½è¡¨è¾¾æ•°æ®
            matrix_file = dataset_dir / 'filtered_feature_bc_matrix.h5'
            if not matrix_file.exists():
                print(f"    ä¸‹è½½è¡¨è¾¾æ•°æ®...")
                urlretrieve(info['matrix_url'], matrix_file)
                print(f"    âœ“ è¡¨è¾¾æ•°æ®ä¸‹è½½å®Œæˆ: {matrix_file.name}")
            
            # ä¸‹è½½ç©ºé—´æ•°æ®
            spatial_archive = dataset_dir / 'spatial.tar.gz'
            if not spatial_archive.exists():
                print(f"    ä¸‹è½½ç©ºé—´æ•°æ®...")
                urlretrieve(info['spatial_url'], spatial_archive)
                
                # è§£å‹ç©ºé—´æ•°æ®
                with tarfile.open(spatial_archive, 'r:gz') as tar:
                    tar.extractall(dataset_dir)
                
                print(f"    âœ“ ç©ºé—´æ•°æ®ä¸‹è½½å¹¶è§£å‹å®Œæˆ")
                
                # åˆ é™¤å‹ç¼©æ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
                spatial_archive.unlink()
            
            # ä½¿ç”¨scanpyè¯»å–å¹¶ä¿å­˜ä¸ºh5ad
            try:
                import scanpy as sc
                h5ad_file = BASE_DIR / f'{dataset_id}.h5ad'
                if not h5ad_file.exists():
                    adata = sc.read_10x_h5(matrix_file)
                    adata.var_names_unique()
                    
                    # è¯»å–ç©ºé—´åæ ‡
                    spatial_dir = dataset_dir / 'spatial'
                    if spatial_dir.exists():
                        # è¯»å–tissue_positions_list.csv
                        positions_file = spatial_dir / 'tissue_positions_list.csv'
                        if positions_file.exists():
                            positions = pd.read_csv(positions_file, header=None, index_col=0)
                            positions.columns = ['in_tissue', 'array_row', 'array_col', 'pxl_row_in_fullres', 'pxl_col_in_fullres']
                            
                            # åŒ¹é…ç»†èƒå¹¶æ·»åŠ ç©ºé—´åæ ‡
                            common_barcodes = adata.obs.index.intersection(positions.index)
                            adata = adata[common_barcodes].copy()
                            adata.obsm['spatial'] = positions.loc[common_barcodes, ['pxl_col_in_fullres', 'pxl_row_in_fullres']].values
                    
                    adata.write(h5ad_file)
                    
                    # è®°å½•å…ƒæ•°æ®
                    log_dataset_info(dataset_id,
                        source='10x_genomics',
                        technology='Visium',
                        description=info['name'],
                        citation=info['citation'],
                        n_cells=adata.n_obs,
                        n_genes=adata.n_vars,
                        has_spatial='spatial' in adata.obsm,
                        file_path=str(h5ad_file.relative_to(BASE_DIR.parent.parent)),
                        file_size_mb=round(h5ad_file.stat().st_size / 1024 / 1024, 2)
                    )
                    
                    print(f"    âœ“ è½¬æ¢ä¸ºh5ad: {adata.n_obs} spots, {adata.n_vars} genes")
            
            except Exception as e:
                print(f"    âš ï¸  è½¬æ¢h5adå¤±è´¥: {e}")
                # ä»ç„¶è®°å½•åŸå§‹æ•°æ®
                log_dataset_info(dataset_id,
                    source='10x_genomics',
                    technology='Visium',
                    description=info['name'],
                    citation=info['citation'],
                    raw_data_dir=str(dataset_dir.relative_to(BASE_DIR.parent.parent)),
                    status='raw_data_only'
                )
                    
        except Exception as e:
            print(f"    âŒ ä¸‹è½½ {dataset_id} å¤±è´¥: {e}")

def download_published_datasets():
    """ä¸‹è½½å·²å‘è¡¨è®ºæ–‡çš„è¡¥å……æ•°æ®"""
    print("\n=== ä¸‹è½½å·²å‘è¡¨è®ºæ–‡æ•°æ® ===")
    
    # å·²çŸ¥çš„é«˜è´¨é‡æ•°æ®é›†é“¾æ¥
    published_datasets = {
        'seqfish_plus_embryo': {
            'name': 'seqFISH+ Mouse Embryo E11.5',
            'description': 'åŸå§‹seqFISH+å°é¼ èƒšèƒæ•°æ®ï¼Œç©ºé—´åˆ†è¾¨ç‡å•ç»†èƒ',
            'citation': 'Lohoff et al., Nature 2022. DOI: 10.1038/s41586-021-04353-z',
            'data_urls': [
                # è¿™äº›URLéœ€è¦æ ¹æ®å®é™…çš„æ•°æ®å¯ç”¨æ€§è¿›è¡Œæ›´æ–°
                # é€šå¸¸åœ¨è®ºæ–‡çš„Data Availabilityéƒ¨åˆ†æˆ–è¡¥å……ææ–™ä¸­æ‰¾åˆ°
            ],
            'geo_accession': 'GSE166692',  # å¦‚æœæœ‰GEOæ•°æ®
        },
        'merfish_hypothalamus': {
            'name': 'MERFISH Mouse Hypothalamus',
            'description': 'åŸå§‹MERFISHå°é¼ ä¸‹ä¸˜è„‘æ•°æ®ï¼Œé«˜é€šé‡ç©ºé—´è½¬å½•ç»„',
            'citation': 'Moffitt et al., Science 2018. DOI: 10.1126/science.aau5324',
            'data_urls': [],
            'note': 'åŸå§‹æ•°æ®å¯èƒ½éœ€è¦ä»ä½œè€…ç›´æ¥è·å–',
        },
        'merfish_motor_cortex': {
            'name': 'MERFISH Human Motor Cortex',
            'description': 'MERFISHäººç±»è¿åŠ¨çš®å±‚æ•°æ®',
            'citation': 'Zhang et al., Science 2023. DOI: 10.1126/science.adf6812',
            'data_urls': [],
            'note': 'BICCNæ•°æ®é›†ï¼Œéœ€è¦ä»BICCNé—¨æˆ·ä¸‹è½½',
        }
    }
    
    for dataset_id, info in published_datasets.items():
        print(f"  {dataset_id}: {info['name']}")
        print(f"    æè¿°: {info['description']}")
        print(f"    å¼•ç”¨: {info['citation']}")
        
        if info.get('geo_accession'):
            print(f"    GEOç™»å½•å·: {info['geo_accession']}")
            print(f"    â„¹ï¸  è¯·æ‰‹åŠ¨ä»GEOä¸‹è½½: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={info['geo_accession']}")
        
        if info.get('note'):
            print(f"    æ³¨æ„: {info['note']}")
        
        # è®°å½•å…ƒæ•°æ®ï¼ˆå³ä½¿æ²¡æœ‰ç›´æ¥ä¸‹è½½ï¼‰
        log_dataset_info(dataset_id,
            source='published_paper',
            description=info['description'],
            citation=info['citation'],
            geo_accession=info.get('geo_accession', ''),
            note=info.get('note', ''),
            status='metadata_only'
        )
        
        print()

def download_demo_datasets():
    """ä¸‹è½½ä¸€äº›è½»é‡çº§çš„æ¼”ç¤ºæ•°æ®é›†ç”¨äºå¿«é€Ÿæµ‹è¯•"""
    print("\n=== åˆ›å»ºæ¼”ç¤ºæ•°æ®é›† ===")
    
    try:
        import squidpy as sq
        
        # ä½¿ç”¨squidpyåˆ›å»ºä¸€äº›å°å‹çš„æ¼”ç¤ºæ•°æ®é›†
        demo_datasets = [
            ('seqfish_demo', 'sq.datasets.seqfish', 'seqFISH+ æ¼”ç¤ºæ•°æ®'),
            ('visium_demo', 'sq.datasets.visium_hne_adata', 'Visium H&E æ¼”ç¤ºæ•°æ®'),
        ]
        
        for demo_name, sq_function, description in demo_datasets:
            try:
                print(f"  åˆ›å»º {demo_name}...")
                
                # åŠ¨æ€è°ƒç”¨squidpyå‡½æ•°
                parts = sq_function.split('.')
                func = sq
                for part in parts[1:]:  # è·³è¿‡'sq'
                    func = getattr(func, part)
                
                adata = func()
                
                # å¦‚æœæ•°æ®å¤ªå¤§ï¼Œè¿›è¡Œä¸‹é‡‡æ ·
                if adata.n_obs > 1000:
                    print(f"    ä¸‹é‡‡æ ·ä» {adata.n_obs} åˆ° 1000 ä¸ªç»†èƒ...")
                    sc.pp.subsample(adata, n_obs=1000, random_state=42)
                
                output_file = BASE_DIR / f'{demo_name}.h5ad'
                adata.write(output_file)
                
                log_dataset_info(demo_name,
                    source='squidpy_demo',
                    description=description,
                    n_cells=adata.n_obs,
                    n_genes=adata.n_vars,
                    has_spatial='spatial' in adata.obsm,
                    file_path=str(output_file.relative_to(BASE_DIR.parent.parent)),
                    file_size_mb=round(output_file.stat().st_size / 1024 / 1024, 2)
                )
                
                print(f"    âœ“ å®Œæˆ: {adata.n_obs} cells, {adata.n_vars} genes")
                
            except Exception as e:
                print(f"    âŒ åˆ›å»º {demo_name} å¤±è´¥: {e}")
    
    except ImportError:
        print("âŒ squidpyæœªå®‰è£…ï¼Œè·³è¿‡æ¼”ç¤ºæ•°æ®é›†")

def create_datasets_readme():
    """åˆ›å»ºæ•°æ®é›†è¯´æ˜æ–‡æ¡£"""
    readme_content = f"""# çœŸå®ç©ºé—´è½¬å½•ç»„æ•°æ®é›†

æœ¬ç›®å½•åŒ…å«ç”¨äºcomprehensive testingçš„çœŸå®ç©ºé—´è½¬å½•ç»„æ•°æ®é›†ã€‚

## æ•°æ®é›†æ¥æº

### 1. Squidpyå†…ç½®æ•°æ®é›†
- ç»è¿‡éªŒè¯çš„æ ‡å‡†æ•°æ®é›†
- æ ¼å¼æ ‡å‡†åŒ–ï¼Œå¯ç›´æ¥ä½¿ç”¨
- åŒ…å«å¤šç§ç©ºé—´è½¬å½•ç»„æŠ€æœ¯

### 2. 10X Genomicså…¬å¼€æ•°æ®é›†  
- VisiumæŠ€æœ¯çš„å®˜æ–¹æ•°æ®
- é«˜è´¨é‡çš„äººç±»å’Œå°é¼ ç»„ç»‡æ•°æ®
- åŒ…å«å®Œæ•´çš„è¡¨è¾¾å’Œç©ºé—´ä¿¡æ¯

### 3. å·²å‘è¡¨è®ºæ–‡æ•°æ®
- æ¥è‡ªé«˜å½±å“å› å­æœŸåˆŠçš„åŸå§‹æ•°æ®
- ä»£è¡¨å„ç§ç©ºé—´è½¬å½•ç»„æŠ€æœ¯çš„æœ€æ–°è¿›å±•
- ç”¨äºéªŒè¯æ–¹æ³•åœ¨çœŸå®æ•°æ®ä¸Šçš„æ€§èƒ½

## æ•°æ®é›†åˆ—è¡¨

è¯¦ç»†çš„æ•°æ®é›†ä¿¡æ¯è¯·æŸ¥çœ‹ `datasets_metadata.json` æ–‡ä»¶ã€‚

## ä½¿ç”¨è¯´æ˜

æ‰€æœ‰æ•°æ®é›†éƒ½ä¿å­˜ä¸º `.h5ad` æ ¼å¼ï¼Œå¯ç›´æ¥ç”¨scanpyåŠ è½½ï¼š

```python
import scanpy as sc

# åŠ è½½æ•°æ®é›†
adata = sc.read_h5ad('squidpy_seqfish.h5ad')

# æŸ¥çœ‹åŸºæœ¬ä¿¡æ¯
print(f"ç»†èƒæ•°: {{adata.n_obs}}")
print(f"åŸºå› æ•°: {{adata.n_vars}}")
print(f"æ˜¯å¦æœ‰ç©ºé—´åæ ‡: {{'spatial' in adata.obsm}}")
```

## å¼•ç”¨ä¿¡æ¯

ä½¿ç”¨è¿™äº›æ•°æ®é›†æ—¶è¯·å¼•ç”¨ç›¸åº”çš„åŸå§‹è®ºæ–‡ï¼Œè¯¦è§metadataä¸­çš„citationå­—æ®µã€‚

## æ›´æ–°æ—¶é—´

æ•°æ®é›†æœ€åæ›´æ–°æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
    
    readme_file = BASE_DIR / 'README.md'
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"âœ“ æ•°æ®é›†è¯´æ˜æ–‡æ¡£ä¿å­˜è‡³: {readme_file}")

def generate_datasets_summary():
    """ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡æ‘˜è¦"""
    print("\n=== ç”Ÿæˆæ•°æ®é›†æ‘˜è¦ ===")
    
    summary = []
    h5ad_files = list(BASE_DIR.glob('*.h5ad'))
    
    for h5ad_file in h5ad_files:
        try:
            adata = sc.read_h5ad(h5ad_file)
            summary.append({
                'dataset': h5ad_file.stem,
                'file_name': h5ad_file.name,
                'n_cells': adata.n_obs,
                'n_genes': adata.n_vars,
                'has_spatial': 'spatial' in adata.obsm,
                'spatial_dims': adata.obsm['spatial'].shape[1] if 'spatial' in adata.obsm else None,
                'file_size_mb': round(h5ad_file.stat().st_size / 1024 / 1024, 2),
                'sparsity': round((adata.X == 0).sum() / adata.X.size, 3) if hasattr(adata.X, 'size') else 'N/A',
                'cell_types': len(adata.obs.columns),
                'gene_metadata': len(adata.var.columns),
            })
        except Exception as e:
            summary.append({
                'dataset': h5ad_file.stem,
                'file_name': h5ad_file.name,
                'error': str(e),
                'file_size_mb': round(h5ad_file.stat().st_size / 1024 / 1024, 2),
            })
    
    if summary:
        summary_df = pd.DataFrame(summary)
        summary_file = BASE_DIR / 'datasets_summary.csv'
        summary_df.to_csv(summary_file, index=False)
        
        print(f"âœ“ æ•°æ®é›†æ‘˜è¦ä¿å­˜è‡³: {summary_file}")
        print(f"\næ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ€»è®¡ h5ad æ–‡ä»¶: {len(h5ad_files)}")
        if not summary_df.empty:
            if 'error' in summary_df.columns:
                valid_datasets = summary_df[~summary_df['error'].notna()]
            else:
                valid_datasets = summary_df
            if not valid_datasets.empty:
                print(f"  æœ‰æ•ˆæ•°æ®é›†: {len(valid_datasets)}")
                print(f"  ç»†èƒæ€»æ•°: {valid_datasets['n_cells'].sum():,}")
                print(f"  å¹³å‡åŸºå› æ•°: {valid_datasets['n_genes'].mean():.0f}")
                print(f"  æ€»æ•°æ®å¤§å°: {valid_datasets['file_size_mb'].sum():.1f} MB")
                print(f"  æœ‰ç©ºé—´ä¿¡æ¯: {valid_datasets['has_spatial'].sum()}/{len(valid_datasets)}")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•h5adæ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ä¸‹è½½çœŸå®ç©ºé—´è½¬å½•ç»„æ•°æ®é›†...")
    print(f"ç›®æ ‡ç›®å½•: {BASE_DIR}")
    
    # æ£€æŸ¥ä¾èµ–
    missing_deps = []
    try:
        import scanpy as sc
        print(f"âœ“ scanpyç‰ˆæœ¬: {sc.__version__}")
    except ImportError:
        missing_deps.append('scanpy')
    
    try:
        import squidpy as sq  
        print(f"âœ“ squidpyç‰ˆæœ¬: {sq.__version__}")
    except ImportError:
        print("âš ï¸  squidpyæœªå®‰è£…ï¼Œéƒ¨åˆ†åŠŸèƒ½å—é™")
    
    if missing_deps:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
        print("è¯·å®‰è£…: pip install scanpy squidpy")
        return
    
    # æ‰§è¡Œä¸‹è½½ä»»åŠ¡
    try:
        download_squidpy_datasets()
        download_10x_genomics_datasets() 
        download_published_datasets()
        download_demo_datasets()
        
        # ç”Ÿæˆæ–‡æ¡£å’Œæ‘˜è¦
        save_metadata()
        create_datasets_readme()
        generate_datasets_summary()
        
        print(f"\nğŸ‰ æ‰€æœ‰æ•°æ®é›†å¤„ç†å®Œæˆï¼")
        print(f"æ•°æ®ä¿å­˜åœ¨: {BASE_DIR}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        h5ad_count = len(list(BASE_DIR.glob('*.h5ad')))
        total_size = sum(f.stat().st_size for f in BASE_DIR.glob('*')) / 1024 / 1024
        
        print(f"\næœ€ç»ˆç»Ÿè®¡:")
        print(f"  h5adæ–‡ä»¶æ•°: {h5ad_count}")
        print(f"  æ€»å ç”¨ç©ºé—´: {total_size:.1f} MB")
        print(f"  å…ƒæ•°æ®è®°å½•: {len(DATASETS_METADATA)} ä¸ªæ•°æ®é›†")
        
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()