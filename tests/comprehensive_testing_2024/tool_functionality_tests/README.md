# ChatSpatial Tool Functionality Tests

This directory contains comprehensive tests for all ChatSpatial tool modules, following spatial transcriptomics analysis best practices and ensuring robust functionality across different data types and scenarios.

## Overview

The test suite covers five core tool modules:

1. **Spatial Analysis Tools** (`spatial_analysis.py`, `spatial_domains.py`, `spatial_genes.py`)
2. **Cell Communication Analysis** (`cell_communication.py`) 
3. **Annotation Tools** (`annotation.py`)
4. **Preprocessing Tools** (`preprocessing.py`)
5. **Visualization Tools** (`visualization.py`)

Each module is tested for:
- âœ… Basic functionality correctness
- ðŸ”§ Parameter validation and edge cases
- ðŸ“Š Output format verification  
- âš¡ Error handling mechanisms
- ðŸ”„ Data type compatibility
- ðŸš€ Performance benchmarks

## Quick Start

### Run Basic Tests (Recommended for Development)
```bash
cd /Users/apple/Research/SpatialTrans_MCP/chatspatial/tests/comprehensive_testing_2024/tool_functionality_tests
python run_comprehensive_tests.py --type basic --verbose
```

### Run All Tests
```bash
python run_comprehensive_tests.py --type all --verbose
```

### Run Performance Benchmarks
```bash
python run_comprehensive_tests.py --type performance --verbose
```

### Run Integration Tests
```bash
python run_comprehensive_tests.py --type integration --verbose
```

### Quick Development Testing (Fast, Stop on First Failure)
```bash
python run_comprehensive_tests.py --type quick --verbose
```

## Test Structure

### Core Test Files

- `test_base.py` - Shared testing utilities and fixtures
- `conftest.py` - Pytest configuration and markers
- `test_spatial_analysis.py` - Spatial analysis tools tests
- `test_spatial_domains.py` - Spatial domains identification tests
- `test_spatial_genes.py` - Spatial gene identification tests
- `test_cell_communication.py` - Cell communication analysis tests
- `test_annotation.py` - Cell type annotation tests
- `test_preprocessing.py` - Data preprocessing tests
- `test_visualization.py` - Visualization tools tests
- `test_performance_benchmarks.py` - Performance and scalability tests
- `run_comprehensive_tests.py` - Test runner and report generator

### Test Categories

Tests are organized using pytest markers:

- **Basic Tests**: Core functionality without external dependencies
- **Slow Tests** (`@slow_test`): Performance and comprehensive tests  
- **Integration Tests** (`@pytest.mark.integration`): End-to-end workflows
- **Dependency Tests** (`@requires_dependency`): Tests requiring specific packages

## Dependencies

### Required Dependencies
- `pytest` - Test framework
- `pytest-asyncio` - Async test support
- `pytest-json-report` - JSON test reporting
- `numpy`, `pandas` - Data manipulation
- `scanpy`, `squidpy` - Spatial transcriptomics
- `matplotlib` - Visualization

### Optional Dependencies (for specific tests)
- `scvi-tools` - scVI-based methods
- `liana` - Cell communication analysis
- `tangram-sc` - Spatial mapping
- `spatialde` - Spatial gene identification
- `cellphonedb` - Cell communication database

## Running Individual Test Modules

### Test Specific Tool Module
```bash
# Test only spatial analysis
pytest test_spatial_analysis.py -v

# Test only cell communication  
pytest test_cell_communication.py -v

# Test only preprocessing
pytest test_preprocessing.py -v
```

### Filter by Test Type
```bash
# Run only basic tests (fast)
pytest -m "not slow and not integration" -v

# Run only performance tests
pytest -m "slow" -v

# Run only integration tests
pytest -m "integration" -v
```

### Filter by Dependencies
```bash
# Skip tests requiring external dependencies
pytest -m "not requires_scvi and not requires_liana" -v

# Run only tests that don't need R
pytest -m "not requires_r" -v
```

## Test Data

Tests use synthetic datasets generated by `create_synthetic_adata()`:

- **Small Dataset**: 100-200 cells, 200-500 genes
- **Medium Dataset**: 300-500 cells, 600-1000 genes  
- **Large Dataset**: 500-1000 cells, 1000-2000 genes

Synthetic data includes:
- Realistic spatial coordinates (grid, random, structured patterns)
- Cell type annotations and clustering
- Expression patterns mimicking real biological signals
- Preprocessing artifacts (PCA, UMAP, neighborhood graphs)

## Performance Benchmarking

The performance test suite measures:

- **Execution Time**: Function runtime across data sizes
- **Memory Usage**: Peak memory consumption and deltas
- **Scalability**: Performance scaling with dataset size
- **Method Comparison**: Relative performance of different methods

### Performance Thresholds

Tests enforce reasonable performance limits:
- Max execution time: 120 seconds per test
- Max memory usage: 1000 MB per test  
- Scaling efficiency: Better than quadratic with data size

### Performance Report

Performance tests generate detailed reports:
```bash
python run_comprehensive_tests.py --type performance
# Generates: performance_report.json
```

## Integration Testing

Integration tests verify:
- **End-to-End Workflows**: Complete analysis pipelines
- **Method Consistency**: Results consistency across runs
- **Real Data Compatibility**: Integration with actual datasets
- **Cross-Module Integration**: Tool interactions

## Error Handling Testing

Comprehensive error handling tests cover:
- Invalid parameters and edge cases
- Malformed or corrupted data
- Missing dependencies
- Memory and resource constraints
- Timeout scenarios

## Test Results and Reporting

### Automated Reporting

The test runner generates comprehensive reports including:
- Test success/failure summary by module
- Performance benchmarks and scaling analysis
- Failed test details with error messages
- Recommendations for fixing issues

### Sample Report Output

```
========================================
ChatSpatial Tool Functionality Test Report
========================================
Test Type: basic
Execution Time: 145.32 seconds
Success: âœ… PASSED

Test Summary:
  Total tests: 127
  Passed: 125
  Failed: 1
  Errors: 0
  Skipped: 1

Results by Module:
  âœ… test_spatial_analysis: 23/23 (100.0% success)
  âœ… test_preprocessing: 28/28 (100.0% success)
  âœ… test_annotation: 19/20 (95.0% success)
  âœ… test_visualization: 24/24 (100.0% success)
  âœ… test_cell_communication: 15/15 (100.0% success)

Recommendations:
  âœ… All tests passed! The ChatSpatial tool functionality is working correctly.
  ðŸ“Š Consider running performance tests if not already done
  ðŸ”„ Run tests regularly during development to catch regressions early
```

## Development Workflow

### Recommended Testing During Development

1. **Quick Tests** during coding:
   ```bash
   python run_comprehensive_tests.py --type quick
   ```

2. **Module-Specific Tests** when modifying a tool:
   ```bash
   pytest test_spatial_analysis.py -v
   ```

3. **Full Basic Tests** before committing:
   ```bash
   python run_comprehensive_tests.py --type basic
   ```

4. **Performance Tests** before releases:
   ```bash
   python run_comprehensive_tests.py --type performance
   ```

### Adding New Tests

When adding new functionality:

1. Add unit tests to the appropriate `test_*.py` file
2. Include parameter validation tests
3. Add error handling tests for edge cases  
4. Consider adding performance tests for slow operations
5. Update integration tests if the change affects workflows

### Test Naming Conventions

- `test_basic_*` - Core functionality tests
- `test_*_validation` - Parameter validation tests  
- `test_*_error_handling` - Error case tests
- `test_*_performance` - Performance benchmarks
- `test_*_integration` - Integration workflow tests

## Troubleshooting

### Common Issues

1. **Import Errors**: Install missing dependencies
   ```bash
   pip install -r requirements-dev.txt
   ```

2. **Memory Issues**: Reduce test dataset sizes or run fewer parallel tests
   ```bash
   pytest --maxfail=1 -x  # Stop on first failure
   ```

3. **Slow Tests**: Skip performance tests during development
   ```bash
   pytest -m "not slow" -v
   ```

4. **Method Not Available**: Tests gracefully skip unavailable methods
   ```
   SKIPPED [1] test_spatial_genes.py: SpatialDE not available
   ```

### Getting Help

- Check test output for detailed error messages
- Review the generated test report for recommendations
- Ensure all dependencies are properly installed
- Consider running tests on smaller datasets for debugging

## Continuous Integration

For CI/CD pipelines:

```bash
# Basic tests (fast, essential)
python run_comprehensive_tests.py --type basic --output ci_basic_report.txt

# Performance tests (slower, for releases)
python run_comprehensive_tests.py --type performance --output ci_perf_report.txt
```

The test runner exits with code 0 on success, non-zero on failure, making it suitable for CI systems.