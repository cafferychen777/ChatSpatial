#!/usr/bin/env python3
"""
å¤„ç†å’ŒéªŒè¯çœŸå®ç©ºé—´è½¬å½•ç»„æ•°æ®é›†çš„è„šæœ¬
å±•ç¤ºå¦‚ä½•å¤„ç†ä¸åŒæ ¼å¼çš„Slide-seqå’ŒSTæ•°æ®
"""

import os
import sys
import scanpy as sc
import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.io
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®scanpy
sc.settings.verbosity = 1
sc.settings.set_figure_params(dpi=80, facecolor='white')

BASE_DIR = Path(__file__).parent / 'datasets' / 'real_datasets'

class SpatialDataProcessor:
    """ç©ºé—´è½¬å½•ç»„æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.processed_dir = self.data_dir / 'processed'
        self.processed_dir.mkdir(exist_ok=True)
        
    def load_and_validate_dataset(self, dataset_name):
        """åŠ è½½å’ŒéªŒè¯æ•°æ®é›†"""
        print(f"\n{'='*60}")
        print(f"å¤„ç†æ•°æ®é›†: {dataset_name}")
        print(f"{'='*60}")
        
        dataset_path = self.data_dir / f"{dataset_name}.h5ad"
        
        if not dataset_path.exists():
            print(f"âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}")
            return None
        
        # åŠ è½½æ•°æ®
        print("ğŸ“ åŠ è½½æ•°æ®é›†...")
        adata = sc.read_h5ad(dataset_path)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"   - Spots: {adata.n_obs:,}")
        print(f"   - Genes: {adata.n_vars:,}") 
        print(f"   - æ•°æ®ç±»å‹: {type(adata.X)}")
        print(f"   - ç¨€ç–æ€§: {(adata.X == 0).sum() / (adata.X.shape[0] * adata.X.shape[1]):.3f}")
        
        # ç©ºé—´ä¿¡æ¯
        if 'spatial' in adata.obsm:
            coords = adata.obsm['spatial']
            print(f"   - ç©ºé—´åæ ‡: {coords.shape}")
            print(f"   - XèŒƒå›´: {coords[:, 0].min():.1f} - {coords[:, 0].max():.1f}")
            print(f"   - YèŒƒå›´: {coords[:, 1].min():.1f} - {coords[:, 1].max():.1f}")
        else:
            print("   - âš ï¸ ç¼ºå°‘ç©ºé—´åæ ‡ä¿¡æ¯")
        
        # æŠ€æœ¯ä¿¡æ¯
        if 'spatial' in adata.uns:
            spatial_info = adata.uns['spatial']
            if 'technology' in spatial_info:
                tech = spatial_info['technology']
                print(f"   - æŠ€æœ¯: {tech.get('technology', 'Unknown')}")
            if 'dataset_info' in spatial_info:
                info = spatial_info['dataset_info']
                print(f"   - æ•°æ®æº: {info.get('source', 'Unknown')}")
                print(f"   - æ¼”ç¤ºæ•°æ®: {info.get('is_demo', False)}")
        
        return adata
    
    def process_slideseq_format(self, count_matrix_path, coordinates_path, output_name):
        """
        å¤„ç†æ ‡å‡†Slide-seqæ ¼å¼æ•°æ®
        
        Parameters:
        -----------
        count_matrix_path : str
            è®¡æ•°çŸ©é˜µæ–‡ä»¶è·¯å¾„ (.csv, .mtx, .h5)
        coordinates_path : str  
            åæ ‡æ–‡ä»¶è·¯å¾„ (.csv)
        output_name : str
            è¾“å‡ºæ–‡ä»¶å
        """
        print(f"\nå¤„ç†Slide-seqæ ¼å¼æ•°æ®: {output_name}")
        
        # è¯»å–è®¡æ•°çŸ©é˜µ
        if count_matrix_path.suffix == '.csv':
            print("  è¯»å–CSVæ ¼å¼è®¡æ•°çŸ©é˜µ...")
            expr_df = pd.read_csv(count_matrix_path, index_col=0)
            X = expr_df.values.T  # è½¬ç½®ï¼šgenes x cells -> cells x genes
            gene_names = expr_df.index.tolist()
            cell_names = expr_df.columns.tolist()
            
        elif count_matrix_path.suffix == '.mtx':
            print("  è¯»å–MTXæ ¼å¼è®¡æ•°çŸ©é˜µ...")
            X = scipy.io.mmread(count_matrix_path).T.tocsr()
            # éœ€è¦é¢å¤–çš„åŸºå› å’Œç»†èƒåç§°æ–‡ä»¶
            gene_names = [f'Gene_{i}' for i in range(X.shape[1])]
            cell_names = [f'Cell_{i}' for i in range(X.shape[0])]
            
        elif count_matrix_path.suffix == '.h5':
            print("  è¯»å–H5æ ¼å¼è®¡æ•°çŸ©é˜µ...")
            import h5py
            with h5py.File(count_matrix_path, 'r') as f:
                # å…·ä½“ç»“æ„å–å†³äº10Xæˆ–å…¶ä»–æ ¼å¼
                pass
        
        # è¯»å–åæ ‡ä¿¡æ¯
        print("  è¯»å–åæ ‡ä¿¡æ¯...")
        coords_df = pd.read_csv(coordinates_path)
        
        # å¸¸è§åˆ—åå˜ç§
        x_col = None
        y_col = None
        for col in coords_df.columns:
            if col.lower() in ['x', 'xcoord', 'x_coord', 'x_coordinate']:
                x_col = col
            elif col.lower() in ['y', 'ycoord', 'y_coord', 'y_coordinate']:
                y_col = col
        
        if x_col is None or y_col is None:
            raise ValueError("æ— æ³•è¯†åˆ«åæ ‡åˆ—")
        
        # åŒ¹é…ç»†èƒ/beads
        if len(coords_df) != len(cell_names):
            print(f"  âš ï¸ åæ ‡æ•°é‡({len(coords_df)})ä¸ç»†èƒæ•°é‡({len(cell_names)})ä¸åŒ¹é…")
            # å°è¯•é€šè¿‡ç´¢å¼•åŒ¹é…
            if 'barcode' in coords_df.columns:
                coords_df = coords_df.set_index('barcode').reindex(cell_names)
        
        # åˆ›å»ºAnnDataå¯¹è±¡
        print("  åˆ›å»ºAnnDataå¯¹è±¡...")
        adata = sc.AnnData(
            X=X,
            obs=pd.DataFrame(index=cell_names),
            var=pd.DataFrame({'gene_symbol': gene_names}, index=gene_names)
        )
        
        adata.obsm['spatial'] = coords_df[[x_col, y_col]].values
        
        # æ·»åŠ æŠ€æœ¯ä¿¡æ¯
        adata.uns['spatial'] = {
            'technology': {
                'technology': 'Slide-seq',
                'bead_diameter': 10,
                'resolution': 'subcellular'
            }
        }
        
        # ä¿å­˜
        output_path = self.processed_dir / f"{output_name}.h5ad"
        adata.write(output_path)
        print(f"  âœ… ä¿å­˜è‡³: {output_path}")
        
        return adata
    
    def process_st_format(self, expression_file, coordinate_file, output_name):
        """
        å¤„ç†æ ‡å‡†STæ ¼å¼æ•°æ®
        
        Parameters:
        -----------
        expression_file : str
            è¡¨è¾¾æ–‡ä»¶è·¯å¾„ (.tsv, .csv)
        coordinate_file : str
            åæ ‡æ–‡ä»¶è·¯å¾„ (.tsv, .csv)
        output_name : str
            è¾“å‡ºæ–‡ä»¶å
        """
        print(f"\nå¤„ç†STæ ¼å¼æ•°æ®: {output_name}")
        
        # è¯»å–è¡¨è¾¾æ•°æ®
        print("  è¯»å–è¡¨è¾¾çŸ©é˜µ...")
        if expression_file.suffix in ['.tsv', '.txt']:
            expr_df = pd.read_csv(expression_file, sep='\t', index_col=0)
        else:
            expr_df = pd.read_csv(expression_file, index_col=0)
        
        # è¯»å–åæ ‡æ•°æ®
        print("  è¯»å–åæ ‡ä¿¡æ¯...")
        if coordinate_file.suffix in ['.tsv', '.txt']:
            coords_df = pd.read_csv(coordinate_file, sep='\t', index_col=0)
        else:
            coords_df = pd.read_csv(coordinate_file, index_col=0)
        
        # STæ•°æ®é€šå¸¸æ˜¯ spots x genes
        X = expr_df.values
        spot_names = expr_df.index.tolist()
        gene_names = expr_df.columns.tolist()
        
        # åŒ¹é…åæ ‡
        coords_df = coords_df.reindex(spot_names)
        
        # åˆ›å»ºAnnData
        print("  åˆ›å»ºAnnDataå¯¹è±¡...")
        adata = sc.AnnData(
            X=X,
            obs=pd.DataFrame(index=spot_names),
            var=pd.DataFrame({'gene_symbol': gene_names}, index=gene_names)
        )
        
        # æ·»åŠ ç©ºé—´åæ ‡
        coord_cols = coords_df.columns[:2]  # é€šå¸¸å‰ä¸¤åˆ—æ˜¯x, y
        adata.obsm['spatial'] = coords_df[coord_cols].values
        
        # æ·»åŠ æŠ€æœ¯ä¿¡æ¯
        adata.uns['spatial'] = {
            'technology': {
                'technology': 'Spatial Transcriptomics',
                'spot_diameter': 100,
                'resolution': 'multi-cellular'
            }
        }
        
        # ä¿å­˜
        output_path = self.processed_dir / f"{output_name}.h5ad"
        adata.write(output_path)
        print(f"  âœ… ä¿å­˜è‡³: {output_path}")
        
        return adata
    
    def validate_data_integrity(self, adata, dataset_name):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        print(f"\nğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§: {dataset_name}")
        
        issues = []
        
        # åŸºæœ¬ç»“æ„æ£€æŸ¥
        if adata.n_obs == 0:
            issues.append("âŒ æ— è§‚æµ‹æ•°æ®(spots)")
        if adata.n_vars == 0:
            issues.append("âŒ æ— åŸºå› æ•°æ®")
        
        # ç©ºé—´åæ ‡æ£€æŸ¥
        if 'spatial' not in adata.obsm:
            issues.append("âŒ ç¼ºå°‘ç©ºé—´åæ ‡")
        else:
            coords = adata.obsm['spatial']
            if coords.shape[1] != 2:
                issues.append(f"âŒ ç©ºé—´åæ ‡ç»´åº¦é”™è¯¯: {coords.shape[1]}")
            if np.any(np.isnan(coords)):
                issues.append("âš ï¸ ç©ºé—´åæ ‡åŒ…å«NaNå€¼")
        
        # è¡¨è¾¾æ•°æ®æ£€æŸ¥
        if np.any(np.isnan(adata.X)):
            issues.append("âš ï¸ è¡¨è¾¾çŸ©é˜µåŒ…å«NaNå€¼")
        if np.any(adata.X < 0):
            issues.append("âš ï¸ è¡¨è¾¾çŸ©é˜µåŒ…å«è´Ÿå€¼")
        
        # ç»Ÿè®¡ä¿¡æ¯
        sparsity = (adata.X == 0).sum() / (adata.X.shape[0] * adata.X.shape[1])
        total_counts = adata.X.sum()
        
        print(f"  ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"     - ç¨€ç–æ€§: {sparsity:.3f}")
        print(f"     - æ€»è®¡æ•°: {total_counts:,.0f}")
        print(f"     - å¹³å‡æ¯spotè®¡æ•°: {total_counts / adata.n_obs:.1f}")
        print(f"     - å¹³å‡æ¯åŸºå› è®¡æ•°: {total_counts / adata.n_vars:.1f}")
        
        if issues:
            print(f"  âš ï¸ å‘ç°é—®é¢˜:")
            for issue in issues:
                print(f"     {issue}")
        else:
            print(f"  âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        
        return len([i for i in issues if i.startswith("âŒ")]) == 0
    
    def create_quality_report(self, dataset_name):
        """åˆ›å»ºæ•°æ®è´¨é‡æŠ¥å‘Š"""
        dataset_path = self.data_dir / f"{dataset_name}.h5ad"
        
        if not dataset_path.exists():
            return
        
        adata = sc.read_h5ad(dataset_path)
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        adata.var['n_cells'] = (adata.X > 0).sum(axis=0).A1
        adata.obs['n_genes'] = (adata.X > 0).sum(axis=1).A1
        adata.obs['total_counts'] = adata.X.sum(axis=1).A1
        
        # åˆ›å»ºè´¨é‡å›¾è¡¨
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(f'æ•°æ®è´¨é‡æŠ¥å‘Š: {dataset_name}', fontsize=16)
        
        # 1. æ¯spotåŸºå› æ•°åˆ†å¸ƒ
        axes[0, 0].hist(adata.obs['n_genes'], bins=50, alpha=0.7)
        axes[0, 0].set_xlabel('Genes per spot')
        axes[0, 0].set_ylabel('Frequency')
        axes[0, 0].set_title('Gene count distribution')
        
        # 2. æ¯spotæ€»è®¡æ•°åˆ†å¸ƒ
        axes[0, 1].hist(adata.obs['total_counts'], bins=50, alpha=0.7)
        axes[0, 1].set_xlabel('Total counts per spot') 
        axes[0, 1].set_ylabel('Frequency')
        axes[0, 1].set_title('UMI count distribution')
        
        # 3. æ¯åŸºå› æ£€å‡ºç»†èƒæ•°åˆ†å¸ƒ
        axes[0, 2].hist(adata.var['n_cells'], bins=50, alpha=0.7)
        axes[0, 2].set_xlabel('Spots per gene')
        axes[0, 2].set_ylabel('Frequency')
        axes[0, 2].set_title('Gene detection distribution')
        
        # 4. ç©ºé—´åˆ†å¸ƒ
        if 'spatial' in adata.obsm:
            coords = adata.obsm['spatial']
            scatter = axes[1, 0].scatter(coords[:, 0], coords[:, 1], 
                                       c=adata.obs['total_counts'], s=1, alpha=0.6)
            axes[1, 0].set_xlabel('X coordinate')
            axes[1, 0].set_ylabel('Y coordinate')
            axes[1, 0].set_title('Spatial UMI distribution')
            plt.colorbar(scatter, ax=axes[1, 0])
        
        # 5. åŸºå› æ•°ç©ºé—´åˆ†å¸ƒ
        if 'spatial' in adata.obsm:
            scatter = axes[1, 1].scatter(coords[:, 0], coords[:, 1],
                                       c=adata.obs['n_genes'], s=1, alpha=0.6)
            axes[1, 1].set_xlabel('X coordinate')
            axes[1, 1].set_ylabel('Y coordinate')
            axes[1, 1].set_title('Spatial gene count distribution')
            plt.colorbar(scatter, ax=axes[1, 1])
        
        # 6. æŠ€æœ¯ç»Ÿè®¡
        axes[1, 2].axis('off')
        stats_text = f"""
æ•°æ®é›†ç»Ÿè®¡:
â€¢ Spots: {adata.n_obs:,}
â€¢ Genes: {adata.n_vars:,}
â€¢ ç¨€ç–æ€§: {(adata.X == 0).sum() / adata.X.size:.3f}
â€¢ ä¸­ä½åŸºå› æ•°/spot: {np.median(adata.obs['n_genes']):.0f}
â€¢ ä¸­ä½UMIæ•°/spot: {np.median(adata.obs['total_counts']):.0f}
â€¢ æ£€å‡ºåŸºå› æ•°: {(adata.var['n_cells'] > 0).sum():,}
        """
        axes[1, 2].text(0.1, 0.5, stats_text, fontsize=11, verticalalignment='center')
        axes[1, 2].set_title('Dataset Statistics')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        plot_path = self.processed_dir / f"{dataset_name}_quality_report.png"
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  ğŸ“Š è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: {plot_path}")
    
    def process_all_datasets(self):
        """å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ•°æ®é›†"""
        print("å¼€å§‹å¤„ç†æ‰€æœ‰çœŸå®æ•°æ®é›†...")
        
        datasets = []
        for h5ad_file in self.data_dir.glob('*.h5ad'):
            dataset_name = h5ad_file.stem
            datasets.append(dataset_name)
        
        print(f"å‘ç° {len(datasets)} ä¸ªæ•°æ®é›†:")
        for ds in datasets:
            print(f"  - {ds}")
        
        # å¤„ç†æ¯ä¸ªæ•°æ®é›†
        results = {}
        for dataset_name in datasets:
            try:
                adata = self.load_and_validate_dataset(dataset_name)
                if adata is not None:
                    valid = self.validate_data_integrity(adata, dataset_name)
                    self.create_quality_report(dataset_name)
                    results[dataset_name] = {'status': 'success', 'valid': valid}
                else:
                    results[dataset_name] = {'status': 'failed', 'valid': False}
                    
            except Exception as e:
                print(f"âŒ å¤„ç† {dataset_name} æ—¶å‡ºé”™: {e}")
                results[dataset_name] = {'status': 'error', 'error': str(e)}
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_processing_summary(results)
        
        return results
    
    def _generate_processing_summary(self, results):
        """ç”Ÿæˆå¤„ç†æ€»ç»“æŠ¥å‘Š"""
        summary_path = self.processed_dir / 'PROCESSING_SUMMARY.md'
        
        success_count = sum(1 for r in results.values() if r.get('status') == 'success')
        valid_count = sum(1 for r in results.values() if r.get('valid') == True)
        
        summary_content = f"""# çœŸå®æ•°æ®é›†å¤„ç†æ€»ç»“æŠ¥å‘Š

å¤„ç†æ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

## å¤„ç†ç»“æœæ¦‚è§ˆ

- **æ€»æ•°æ®é›†**: {len(results)}
- **æˆåŠŸå¤„ç†**: {success_count}
- **æ•°æ®å®Œæ•´**: {valid_count}
- **æˆåŠŸç‡**: {success_count/len(results)*100:.1f}%

## è¯¦ç»†ç»“æœ

"""
        
        for dataset_name, result in results.items():
            status = result.get('status', 'unknown')
            valid = result.get('valid', False)
            
            if status == 'success':
                status_icon = 'âœ…'
                valid_icon = 'âœ…' if valid else 'âš ï¸'
            elif status == 'failed':
                status_icon = 'âŒ'
                valid_icon = 'âŒ'
            else:
                status_icon = 'âŒ'
                valid_icon = 'âŒ'
            
            summary_content += f"### {dataset_name}\n"
            summary_content += f"- **å¤„ç†çŠ¶æ€**: {status_icon} {status}\n"
            summary_content += f"- **æ•°æ®å®Œæ•´æ€§**: {valid_icon} {'é€šè¿‡' if valid else 'æœ‰é—®é¢˜'}\n"
            
            if 'error' in result:
                summary_content += f"- **é”™è¯¯ä¿¡æ¯**: {result['error']}\n"
            
            summary_content += "\n"
        
        summary_content += """
## ä½¿ç”¨å»ºè®®

### é«˜è´¨é‡æ•°æ®é›†
æ¨èç”¨äºæ­£å¼åˆ†æçš„æ•°æ®é›†ï¼ˆå¤„ç†æˆåŠŸä¸”æ•°æ®å®Œæ•´ï¼‰

### é—®é¢˜æ•°æ®é›†  
éœ€è¦è¿›ä¸€æ­¥æ¸…ç†æˆ–ä¿®å¤çš„æ•°æ®é›†

### è´¨é‡æŠ¥å‘Š
æ¯ä¸ªæ•°æ®é›†çš„è¯¦ç»†è´¨é‡æŠ¥å‘Šå›¾è¡¨å·²ä¿å­˜åœ¨ `processed/` ç›®å½•ä¸­

---
*æ­¤æŠ¥å‘Šç”± SpatialDataProcessor è‡ªåŠ¨ç”Ÿæˆ*
"""
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(summary_content)
        
        print(f"\nğŸ“‹ å¤„ç†æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("çœŸå®ç©ºé—´è½¬å½•ç»„æ•°æ®é›†å¤„ç†å™¨")
    print("=" * 80)
    
    processor = SpatialDataProcessor(BASE_DIR)
    results = processor.process_all_datasets()
    
    print("\n" + "=" * 80)
    print("å¤„ç†å®Œæˆï¼")
    print(f"å¤„ç†ç»“æœä¿å­˜åœ¨: {processor.processed_dir}")
    print("=" * 80)


if __name__ == "__main__":
    main()