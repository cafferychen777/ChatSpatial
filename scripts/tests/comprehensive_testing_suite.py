#!/usr/bin/env python3
"""
è¶…å…¨é¢æµ‹è¯•å¥—ä»¶ - æ·±åº¦æµ‹è¯•å¯è§†åŒ–å¢å¼ºåŠŸèƒ½
åŒ…æ‹¬è¾¹ç•Œæƒ…å†µã€å‹åŠ›æµ‹è¯•ã€çœŸå®åœºæ™¯ã€é”™è¯¯å¤„ç†ã€æ€§èƒ½æµ‹è¯•ç­‰
"""

import asyncio
import sys
import os
import time
import numpy as np
import pandas as pd
import scanpy as sc
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Add the project root to the path
sys.path.insert(0, str(Path(__file__).parent))

from chatspatial.models.data import VisualizationParameters
from chatspatial.tools.visualization import visualize_data
from chatspatial.utils.image_utils import fig_to_image


class ComprehensiveTestSuite:
    """è¶…å…¨é¢æµ‹è¯•å¥—ä»¶ç±»"""
    
    def __init__(self):
        self.test_results = {}
        self.performance_results = {}
        self.data_variants = {}
        
    def create_various_test_datasets(self):
        """åˆ›å»ºå„ç§ç±»å‹çš„æµ‹è¯•æ•°æ®é›†"""
        print("ğŸ”„ åˆ›å»ºå¤šç§æµ‹è¯•æ•°æ®é›†...")
        
        datasets = {}
        
        # 1. å°æ•°æ®é›† (è¾¹ç•Œæƒ…å†µ)
        datasets['tiny'] = self._create_tiny_dataset()
        
        # 2. ä¸­ç­‰æ•°æ®é›† (æ ‡å‡†åœºæ™¯)
        datasets['medium'] = self._create_medium_dataset()
        
        # 3. å¤§æ•°æ®é›† (æ€§èƒ½æµ‹è¯•)
        datasets['large'] = self._create_large_dataset()
        
        # 4. ç¨€ç–æ•°æ®é›† (ç‰¹æ®Šæƒ…å†µ)
        datasets['sparse'] = self._create_sparse_dataset()
        
        # 5. ä¸å¹³è¡¡æ•°æ®é›† (çœŸå®åœºæ™¯)
        datasets['imbalanced'] = self._create_imbalanced_dataset()
        
        # 6. æœ‰ç¼ºå¤±å€¼çš„æ•°æ®é›†
        datasets['missing_data'] = self._create_missing_data_dataset()
        
        # 7. 10x Visiumé£æ ¼æ•°æ®é›†
        datasets['visium'] = self._create_visium_style_dataset()
        
        # 8. æç«¯å€¼æ•°æ®é›†
        datasets['extreme_values'] = self._create_extreme_values_dataset()
        
        self.data_variants = datasets
        print(f"âœ… åˆ›å»ºäº† {len(datasets)} ä¸ªæµ‹è¯•æ•°æ®é›†")
        return datasets
    
    def _create_tiny_dataset(self):
        """åˆ›å»ºæå°æ•°æ®é›† (è¾¹ç•Œæµ‹è¯•)"""
        n_cells, n_genes = 10, 20
        np.random.seed(42)
        
        adata = sc.AnnData(
            X=np.random.poisson(2, (n_cells, n_genes)).astype(np.float32),
            obs=pd.DataFrame(index=[f"Cell_{i}" for i in range(n_cells)]),
            var=pd.DataFrame(index=[f"Gene_{i}" for i in range(n_genes)])
        )
        
        # æç®€ç©ºé—´åæ ‡
        adata.obsm['spatial'] = np.random.normal(0, 1, (n_cells, 2))
        adata.obs['leiden'] = pd.Categorical(['A', 'B'] * 5)
        adata.obs['batch'] = pd.Categorical(['Batch1'] * 10)
        
        return adata
    
    def _create_medium_dataset(self):
        """åˆ›å»ºä¸­ç­‰æ•°æ®é›† (æ ‡å‡†æµ‹è¯•)"""
        n_cells, n_genes = 500, 1000
        np.random.seed(123)
        
        adata = sc.AnnData(
            X=np.random.poisson(5, (n_cells, n_genes)).astype(np.float32),
            obs=pd.DataFrame(index=[f"Cell_{i:04d}" for i in range(n_cells)]),
            var=pd.DataFrame(index=[f"Gene_{i:04d}" for i in range(n_genes)])
        )
        
        # ç©ºé—´åæ ‡ - å½¢æˆæ˜æ˜¾çš„cluster
        centers = np.array([[0, 0], [10, 0], [5, 8], [-5, 5]])
        cluster_labels = []
        coords = []
        
        for i in range(n_cells):
            cluster_idx = i % 4
            center = centers[cluster_idx]
            coord = center + np.random.normal(0, 2, 2)
            coords.append(coord)
            cluster_labels.append(f"Cluster_{cluster_idx}")
        
        adata.obsm['spatial'] = np.array(coords)
        adata.obs['leiden'] = pd.Categorical(cluster_labels)
        adata.obs['batch'] = pd.Categorical(np.random.choice(['Batch1', 'Batch2'], n_cells))
        adata.obs['cell_type'] = pd.Categorical(np.random.choice(['TypeA', 'TypeB', 'TypeC'], n_cells))
        
        # æ·»åŠ é«˜å˜åŸºå› 
        sc.pp.highly_variable_genes(adata, n_top_genes=100)
        
        # è®¡ç®—é‚»å±…å’ŒUMAP
        sc.pp.neighbors(adata, n_neighbors=10)
        sc.tl.umap(adata)
        
        # æ·»åŠ é‚»åŸŸå¯Œé›†ç»“æœ
        n_clusters = len(adata.obs['leiden'].cat.categories)
        enrichment_matrix = np.random.normal(0, 1.5, (n_clusters, n_clusters))
        enrichment_matrix = (enrichment_matrix + enrichment_matrix.T) / 2
        np.fill_diagonal(enrichment_matrix, np.abs(np.diagonal(enrichment_matrix)) + 2)
        
        adata.uns['leiden_nhood_enrichment'] = {'zscore': enrichment_matrix}
        
        return adata
    
    def _create_large_dataset(self):
        """åˆ›å»ºå¤§æ•°æ®é›† (æ€§èƒ½æµ‹è¯•)"""
        n_cells, n_genes = 5000, 3000
        np.random.seed(456)
        
        # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®ç”Ÿæˆ
        from scipy.sparse import csr_matrix
        
        # ç”Ÿæˆç¨€ç–çŸ©é˜µä»¥èŠ‚çœå†…å­˜
        density = 0.1  # 10%çš„éé›¶å€¼
        X_data = np.random.poisson(3, int(n_cells * n_genes * density))
        row_indices = np.random.randint(0, n_cells, len(X_data))
        col_indices = np.random.randint(0, n_genes, len(X_data))
        X_sparse = csr_matrix((X_data, (row_indices, col_indices)), shape=(n_cells, n_genes))
        
        adata = sc.AnnData(
            X=X_sparse.astype(np.float32),
            obs=pd.DataFrame(index=[f"Cell_{i:05d}" for i in range(n_cells)]),
            var=pd.DataFrame(index=[f"Gene_{i:04d}" for i in range(n_genes)])
        )
        
        # å¤§è§„æ¨¡ç©ºé—´åæ ‡
        adata.obsm['spatial'] = np.random.normal(0, 20, (n_cells, 2))
        
        # æ›´å¤šcluster
        n_clusters = 10
        cluster_labels = [f"Cluster_{i%n_clusters}" for i in range(n_cells)]
        adata.obs['leiden'] = pd.Categorical(cluster_labels)
        adata.obs['batch'] = pd.Categorical(np.random.choice(['B1', 'B2', 'B3', 'B4'], n_cells))
        
        return adata
    
    def _create_sparse_dataset(self):
        """åˆ›å»ºç¨€ç–æ•°æ®é›†"""
        n_cells, n_genes = 200, 500
        np.random.seed(789)
        
        # æåº¦ç¨€ç–çš„æ•°æ® (90%çš„é›¶å€¼)
        X = np.random.poisson(0.5, (n_cells, n_genes)).astype(np.float32)
        X[X > 3] = 0  # è¿›ä¸€æ­¥å¢åŠ ç¨€ç–æ€§
        
        adata = sc.AnnData(
            X=X,
            obs=pd.DataFrame(index=[f"Cell_{i}" for i in range(n_cells)]),
            var=pd.DataFrame(index=[f"Gene_{i}" for i in range(n_genes)])
        )
        
        adata.obsm['spatial'] = np.random.normal(0, 5, (n_cells, 2))
        adata.obs['leiden'] = pd.Categorical(['Sparse_A', 'Sparse_B', 'Sparse_C'] * (n_cells//3 + 1))[:n_cells]
        adata.obs['batch'] = pd.Categorical(['SparseBatch'] * n_cells)
        
        return adata
    
    def _create_imbalanced_dataset(self):
        """åˆ›å»ºä¸å¹³è¡¡æ•°æ®é›† (æ¨¡æ‹ŸçœŸå®åœºæ™¯)"""
        n_cells, n_genes = 800, 1200
        np.random.seed(321)
        
        adata = sc.AnnData(
            X=np.random.poisson(4, (n_cells, n_genes)).astype(np.float32),
            obs=pd.DataFrame(index=[f"Cell_{i:04d}" for i in range(n_cells)]),
            var=pd.DataFrame(index=[f"Gene_{i:04d}" for i in range(n_genes)])
        )
        
        adata.obsm['spatial'] = np.random.normal(0, 15, (n_cells, 2))
        
        # æä¸å¹³è¡¡çš„clusteråˆ†å¸ƒ (æ¨¡æ‹Ÿç¨€æœ‰ç»†èƒç±»å‹)
        cluster_sizes = [500, 200, 50, 30, 20]  # ä¸¥é‡ä¸å¹³è¡¡
        cluster_labels = []
        for i, size in enumerate(cluster_sizes):
            cluster_labels.extend([f"Type_{i}"] * size)
        
        adata.obs['leiden'] = pd.Categorical(cluster_labels[:n_cells])
        adata.obs['batch'] = pd.Categorical(['Imbalanced_B1', 'Imbalanced_B2'] * (n_cells//2))
        
        return adata
    
    def _create_missing_data_dataset(self):
        """åˆ›å»ºæœ‰ç¼ºå¤±æ•°æ®çš„æ•°æ®é›†"""
        n_cells, n_genes = 300, 600
        np.random.seed(654)
        
        adata = sc.AnnData(
            X=np.random.poisson(3, (n_cells, n_genes)).astype(np.float32),
            obs=pd.DataFrame(index=[f"Cell_{i}" for i in range(n_cells)]),
            var=pd.DataFrame(index=[f"Gene_{i}" for i in range(n_genes)])
        )
        
        adata.obsm['spatial'] = np.random.normal(0, 8, (n_cells, 2))
        
        # éƒ¨åˆ†ç¼ºå¤±çš„metadata
        leiden_labels = ['Missing_A', 'Missing_B', 'Missing_C'] * (n_cells//3)
        leiden_labels = leiden_labels[:n_cells]
        # éšæœºè®¾ç½®ä¸€äº›ä¸ºNaN
        leiden_labels = pd.Categorical(leiden_labels)
        
        adata.obs['leiden'] = leiden_labels
        adata.obs['batch'] = pd.Categorical(['MissingBatch'] * n_cells)
        
        # æ•…æ„ä¸æ·»åŠ UMAPå’Œneighbors (æµ‹è¯•ç¼ºå¤±æ•°æ®å¤„ç†)
        
        return adata
    
    def _create_visium_style_dataset(self):
        """åˆ›å»º10x Visiumé£æ ¼çš„æ•°æ®é›†"""
        n_cells, n_genes = 400, 800
        np.random.seed(987)
        
        adata = sc.AnnData(
            X=np.random.negative_binomial(10, 0.3, (n_cells, n_genes)).astype(np.float32),
            obs=pd.DataFrame(index=[f"AAACAAGTATCTCCCA-1_{i}" for i in range(n_cells)]),
            var=pd.DataFrame(index=[f"Gene_{i}" for i in range(n_genes)])
        )
        
        # Visiumå¼çš„å…­è¾¹å½¢ç½‘æ ¼åæ ‡
        coords = []
        for i in range(n_cells):
            row = i // 20
            col = i % 20
            x = col + (row % 2) * 0.5  # å…­è¾¹å½¢åç§»
            y = row * 0.866  # å…­è¾¹å½¢é—´è·
            coords.append([x * 100, y * 100])
        
        adata.obsm['spatial'] = np.array(coords)
        
        # æ·»åŠ Visiumé£æ ¼çš„metadata
        adata.obs['leiden'] = pd.Categorical([f"Visium_{i%6}" for i in range(n_cells)])
        adata.obs['batch'] = pd.Categorical(['V1'] * n_cells)
        
        # æ¨¡æ‹Ÿç»„ç»‡å›¾åƒä¿¡æ¯
        adata.uns['spatial'] = {
            'V1': {
                'images': {'hires': np.random.rand(100, 100, 3)},
                'scalefactors': {'tissue_hires_scalef': 0.1}
            }
        }
        
        return adata
    
    def _create_extreme_values_dataset(self):
        """åˆ›å»ºåŒ…å«æç«¯å€¼çš„æ•°æ®é›†"""
        n_cells, n_genes = 150, 300
        np.random.seed(111)
        
        X = np.random.poisson(2, (n_cells, n_genes)).astype(np.float32)
        
        # æ·»åŠ ä¸€äº›æç«¯å€¼
        X[0, 0] = 1000000  # æå¤§å€¼
        X[1, 1] = 0        # æå°å€¼
        X[np.random.choice(n_cells, 10), np.random.choice(n_genes, 10)] = np.inf  # æ— ç©·å¤§
        X[np.random.choice(n_cells, 5), np.random.choice(n_genes, 5)] = -np.inf   # è´Ÿæ— ç©·å¤§
        X[np.random.choice(n_cells, 3), np.random.choice(n_genes, 3)] = np.nan    # NaNå€¼
        
        adata = sc.AnnData(
            X=X,
            obs=pd.DataFrame(index=[f"Extreme_{i}" for i in range(n_cells)]),
            var=pd.DataFrame(index=[f"Gene_{i}" for i in range(n_genes)])
        )
        
        adata.obsm['spatial'] = np.random.normal(0, 10, (n_cells, 2))
        adata.obs['leiden'] = pd.Categorical(['Extreme_A', 'Extreme_B'] * (n_cells//2 + 1))[:n_cells]
        adata.obs['batch'] = pd.Categorical(['ExtremeBatch'] * n_cells)
        
        return adata


    async def run_edge_case_tests(self):
        """è¿è¡Œè¾¹ç•Œæƒ…å†µæµ‹è¯•"""
        print("\nğŸ§ª è¿è¡Œè¾¹ç•Œæƒ…å†µæµ‹è¯•...")
        
        edge_results = {}
        
        # æµ‹è¯•1: ç©ºå‚æ•°
        edge_results['empty_params'] = await self._test_empty_parameters()
        
        # æµ‹è¯•2: æ— æ•ˆplot_type
        edge_results['invalid_plot_type'] = await self._test_invalid_plot_type()
        
        # æµ‹è¯•3: ä¸å­˜åœ¨çš„ç‰¹å¾
        edge_results['nonexistent_feature'] = await self._test_nonexistent_feature()
        
        # æµ‹è¯•4: æå°æ•°æ®é›†
        edge_results['tiny_dataset'] = await self._test_tiny_dataset()
        
        # æµ‹è¯•5: ç¼ºå¤±å…³é”®æ•°æ®
        edge_results['missing_key_data'] = await self._test_missing_key_data()
        
        # æµ‹è¯•6: æç«¯å‚æ•°å€¼
        edge_results['extreme_parameters'] = await self._test_extreme_parameters()
        
        # æµ‹è¯•7: å†…å­˜é™åˆ¶
        edge_results['memory_limit'] = await self._test_memory_constraints()
        
        return edge_results
    
    async def _test_empty_parameters(self):
        """æµ‹è¯•ç©ºå‚æ•°å¤„ç†"""
        try:
            data_store = {"test": {"adata": self.data_variants['medium']}}
            params = VisualizationParameters()  # å®Œå…¨é»˜è®¤å‚æ•°
            result = await visualize_data("test", data_store, params)
            return True
        except Exception as e:
            print(f"âŒ ç©ºå‚æ•°æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_invalid_plot_type(self):
        """æµ‹è¯•æ— æ•ˆplot_typeå¤„ç†"""
        try:
            data_store = {"test": {"adata": self.data_variants['medium']}}
            params = VisualizationParameters(plot_type="invalid_type_xyz")
            result = await visualize_data("test", data_store, params)
            return False  # åº”è¯¥æŠ›å‡ºå¼‚å¸¸
        except Exception as e:
            # é¢„æœŸçš„å¼‚å¸¸
            return "Invalid plot_type" in str(e) or "invalid_type_xyz" in str(e)
    
    async def _test_nonexistent_feature(self):
        """æµ‹è¯•ä¸å­˜åœ¨çš„ç‰¹å¾å¤„ç†"""
        try:
            data_store = {"test": {"adata": self.data_variants['medium']}}
            params = VisualizationParameters(
                plot_type="spatial",
                feature="NonExistentGene_XYZ123"
            )
            result = await visualize_data("test", data_store, params)
            return True  # åº”è¯¥ä¼˜é›…å¤„ç†
        except Exception as e:
            print(f"âŒ ä¸å­˜åœ¨ç‰¹å¾æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_tiny_dataset(self):
        """æµ‹è¯•æå°æ•°æ®é›†å¤„ç†"""
        try:
            data_store = {"test": {"adata": self.data_variants['tiny']}}
            
            # æµ‹è¯•å¤šç§plotç±»å‹
            plot_types = ["spatial", "umap", "heatmap"]
            
            for plot_type in plot_types:
                params = VisualizationParameters(plot_type=plot_type)
                result = await visualize_data("test", data_store, params)
            
            return True
        except Exception as e:
            print(f"âŒ æå°æ•°æ®é›†æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_missing_key_data(self):
        """æµ‹è¯•ç¼ºå¤±å…³é”®æ•°æ®å¤„ç†"""
        try:
            data_store = {"test": {"adata": self.data_variants['missing_data']}}
            
            # æµ‹è¯•éœ€è¦UMAPä½†æ•°æ®ä¸­æ²¡æœ‰çš„æƒ…å†µ
            params = VisualizationParameters(
                plot_type="umap",
                show_velocity=True,
                show_trajectory=True
            )
            result = await visualize_data("test", data_store, params)
            return True  # åº”è¯¥ä¼˜é›…å¤„ç†ç¼ºå¤±æ•°æ®
        except Exception as e:
            print(f"âŒ ç¼ºå¤±å…³é”®æ•°æ®æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_extreme_parameters(self):
        """æµ‹è¯•æç«¯å‚æ•°å€¼"""
        try:
            data_store = {"test": {"adata": self.data_variants['medium']}}
            
            # æµ‹è¯•æç«¯å‚æ•°å€¼
            extreme_params = [
                VisualizationParameters(
                    plot_type="spatial",
                    figure_size=(1, 1),  # æå°å›¾åƒ
                    dpi=10  # æä½DPI
                ),
                VisualizationParameters(
                    plot_type="umap",
                    figure_size=(50, 50),  # æå¤§å›¾åƒ
                    dpi=300,  # æé«˜DPI
                    alpha=0.0  # å®Œå…¨é€æ˜
                ),
                VisualizationParameters(
                    plot_type="spatial_analysis",
                    analysis_sub_type="neighborhood",
                    network_threshold=1000.0,  # æé«˜é˜ˆå€¼
                    show_network=True
                )
            ]
            
            for params in extreme_params:
                result = await visualize_data("test", data_store, params)
            
            return True
        except Exception as e:
            print(f"âŒ æç«¯å‚æ•°æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_memory_constraints(self):
        """æµ‹è¯•å†…å­˜çº¦æŸå¤„ç†"""
        try:
            data_store = {"test": {"adata": self.data_variants['large']}}
            
            # æµ‹è¯•å¤§æ•°æ®é›†çš„å†…å­˜ä½¿ç”¨
            params = VisualizationParameters(
                plot_type="heatmap",
                obs_annotation=["leiden", "batch"]
            )
            
            # ç›‘æ§å†…å­˜ä½¿ç”¨
            import psutil
            process = psutil.Process()
            memory_before = process.memory_info().rss / 1024 / 1024  # MB
            
            result = await visualize_data("test", data_store, params)
            
            memory_after = process.memory_info().rss / 1024 / 1024  # MB
            memory_used = memory_after - memory_before
            
            print(f"ğŸ“Š å†…å­˜ä½¿ç”¨: {memory_used:.1f} MB")
            
            return memory_used < 1000  # é™åˆ¶åœ¨1GBå†…
        except Exception as e:
            print(f"âŒ å†…å­˜çº¦æŸæµ‹è¯•å¤±è´¥: {str(e)}")
            return False


    async def run_performance_tests(self):
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        print("\nâš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•...")
        
        performance_results = {}
        
        # æµ‹è¯•ä¸åŒæ•°æ®é›†å¤§å°çš„æ€§èƒ½
        for dataset_name, adata in self.data_variants.items():
            print(f"  ğŸ“Š æµ‹è¯•æ•°æ®é›†: {dataset_name} ({adata.n_obs} cells, {adata.n_vars} genes)")
            
            data_store = {"test": {"adata": adata}}
            
            # æµ‹è¯•ä¸åŒç±»å‹çš„å¯è§†åŒ–æ€§èƒ½
            visualizations = [
                ("spatial", VisualizationParameters(plot_type="spatial", feature="Gene_0")),
                ("umap", VisualizationParameters(plot_type="umap", feature="leiden")),
                ("heatmap", VisualizationParameters(plot_type="heatmap")),
                ("spatial_interaction", VisualizationParameters(
                    plot_type="spatial_interaction",
                    lr_pairs=[("Gene_0", "Gene_1")]
                )),
                ("integration_check", VisualizationParameters(
                    plot_type="integration_check",
                    batch_key="batch"
                ))
            ]
            
            dataset_performance = {}
            
            for viz_name, params in visualizations:
                start_time = time.time()
                
                try:
                    result = await visualize_data("test", data_store, params)
                    end_time = time.time()
                    execution_time = end_time - start_time
                    
                    dataset_performance[viz_name] = {
                        'success': True,
                        'time': execution_time,
                        'time_per_cell': execution_time / adata.n_obs * 1000  # ms per cell
                    }
                    
                    print(f"    âœ… {viz_name}: {execution_time:.2f}s ({execution_time/adata.n_obs*1000:.2f}ms/cell)")
                    
                except Exception as e:
                    end_time = time.time()
                    execution_time = end_time - start_time
                    
                    dataset_performance[viz_name] = {
                        'success': False,
                        'time': execution_time,
                        'error': str(e)
                    }
                    
                    print(f"    âŒ {viz_name}: FAILED in {execution_time:.2f}s - {str(e)[:50]}...")
            
            performance_results[dataset_name] = dataset_performance
        
        self.performance_results = performance_results
        return performance_results


    async def run_stress_tests(self):
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        print("\nğŸ’ª è¿è¡Œå‹åŠ›æµ‹è¯•...")
        
        stress_results = {}
        
        # å‹åŠ›æµ‹è¯•1: å¿«é€Ÿè¿ç»­è°ƒç”¨
        stress_results['rapid_calls'] = await self._test_rapid_calls()
        
        # å‹åŠ›æµ‹è¯•2: å¹¶å‘è°ƒç”¨
        stress_results['concurrent_calls'] = await self._test_concurrent_calls()
        
        # å‹åŠ›æµ‹è¯•3: å¤šç§å‚æ•°ç»„åˆ
        stress_results['parameter_combinations'] = await self._test_parameter_combinations()
        
        # å‹åŠ›æµ‹è¯•4: æç«¯æ•°æ®å¤„ç†
        stress_results['extreme_data'] = await self._test_extreme_data_handling()
        
        return stress_results
    
    async def _test_rapid_calls(self):
        """æµ‹è¯•å¿«é€Ÿè¿ç»­è°ƒç”¨"""
        try:
            data_store = {"test": {"adata": self.data_variants['medium']}}
            params = VisualizationParameters(plot_type="spatial", feature="Gene_0")
            
            start_time = time.time()
            
            # å¿«é€Ÿè¿ç»­è°ƒç”¨50æ¬¡
            for i in range(50):
                result = await visualize_data("test", data_store, params)
            
            end_time = time.time()
            total_time = end_time - start_time
            avg_time = total_time / 50
            
            print(f"    ğŸ“ˆ 50æ¬¡è¿ç»­è°ƒç”¨: {total_time:.2f}s (å¹³å‡ {avg_time:.3f}s/æ¬¡)")
            
            return avg_time < 1.0  # æ¯æ¬¡è°ƒç”¨åº”è¯¥åœ¨1ç§’å†…
            
        except Exception as e:
            print(f"    âŒ å¿«é€Ÿè°ƒç”¨æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_concurrent_calls(self):
        """æµ‹è¯•å¹¶å‘è°ƒç”¨"""
        try:
            data_store = {"test": {"adata": self.data_variants['medium']}}
            
            # åˆ›å»ºä¸åŒçš„å¯è§†åŒ–ä»»åŠ¡
            tasks = []
            
            visualizations = [
                VisualizationParameters(plot_type="spatial", feature="Gene_0"),
                VisualizationParameters(plot_type="umap", feature="leiden"),
                VisualizationParameters(plot_type="heatmap"),
                VisualizationParameters(plot_type="spatial_interaction", lr_pairs=[("Gene_0", "Gene_1")]),
                VisualizationParameters(plot_type="integration_check", batch_key="batch")
            ]
            
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            for i, params in enumerate(visualizations * 3):  # æ¯ç§ç±»å‹é‡å¤3æ¬¡
                task = asyncio.create_task(visualize_data("test", data_store, params))
                tasks.append(task)
            
            start_time = time.time()
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            end_time = time.time()
            total_time = end_time - start_time
            
            # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥
            successful = sum(1 for r in results if not isinstance(r, Exception))
            failed = len(results) - successful
            
            print(f"    ğŸš€ 15ä¸ªå¹¶å‘ä»»åŠ¡: {total_time:.2f}s, æˆåŠŸ: {successful}, å¤±è´¥: {failed}")
            
            return successful >= 12  # è‡³å°‘80%æˆåŠŸ
            
        except Exception as e:
            print(f"    âŒ å¹¶å‘è°ƒç”¨æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_parameter_combinations(self):
        """æµ‹è¯•å¤šç§å‚æ•°ç»„åˆ"""
        try:
            data_store = {"test": {"adata": self.data_variants['medium']}}
            
            # ç”Ÿæˆå„ç§å‚æ•°ç»„åˆ
            combinations = [
                # ç©ºé—´å›¾ç»„åˆ
                {"plot_type": "spatial", "feature": "Gene_0", "add_outline": True, "outline_cluster_key": "leiden"},
                {"plot_type": "spatial", "feature": "leiden", "add_outline": True, "outline_color": "red"},
                
                # UMAPç»„åˆ
                {"plot_type": "umap", "feature": "leiden", "size_by": "Gene_0"},
                {"plot_type": "umap", "feature": "Gene_0", "show_velocity": True, "show_trajectory": True},
                
                # çƒ­å›¾ç»„åˆ
                {"plot_type": "heatmap", "obs_annotation": ["leiden"]},
                {"plot_type": "heatmap", "obs_annotation": ["leiden", "batch", "cell_type"]},
                
                # ç©ºé—´åˆ†æç»„åˆ
                {"plot_type": "spatial_analysis", "analysis_sub_type": "neighborhood", "cluster_key": "leiden"},
                {"plot_type": "spatial_analysis", "analysis_sub_type": "neighborhood", "show_network": True, "network_threshold": 1.0},
                
                # æ–°åŠŸèƒ½ç»„åˆ
                {"plot_type": "spatial_interaction", "lr_pairs": [("Gene_0", "Gene_1"), ("Gene_2", "Gene_3")]},
                {"plot_type": "integration_check", "batch_key": "batch", "integration_method": "TestMethod"}
            ]
            
            successful = 0
            
            for i, combo in enumerate(combinations):
                try:
                    params = VisualizationParameters(**combo)
                    result = await visualize_data("test", data_store, params)
                    successful += 1
                    print(f"    âœ… ç»„åˆ {i+1}: {combo['plot_type']} æˆåŠŸ")
                except Exception as e:
                    print(f"    âŒ ç»„åˆ {i+1}: {combo['plot_type']} å¤±è´¥ - {str(e)[:30]}...")
            
            success_rate = successful / len(combinations)
            print(f"    ğŸ“Š å‚æ•°ç»„åˆæˆåŠŸç‡: {success_rate*100:.1f}% ({successful}/{len(combinations)})")
            
            return success_rate >= 0.8
            
        except Exception as e:
            print(f"    âŒ å‚æ•°ç»„åˆæµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_extreme_data_handling(self):
        """æµ‹è¯•æç«¯æ•°æ®å¤„ç†"""
        try:
            data_store = {"test": {"adata": self.data_variants['extreme_values']}}
            
            # æµ‹è¯•å„ç§å¯è§†åŒ–ç±»å‹å¯¹æç«¯å€¼çš„å¤„ç†
            visualizations = [
                VisualizationParameters(plot_type="spatial", feature="Gene_0"),
                VisualizationParameters(plot_type="umap", feature="Gene_1"),
                VisualizationParameters(plot_type="heatmap")
            ]
            
            successful = 0
            
            for params in visualizations:
                try:
                    result = await visualize_data("test", data_store, params)
                    successful += 1
                    print(f"    âœ… æç«¯å€¼å¤„ç†: {params.plot_type} æˆåŠŸ")
                except Exception as e:
                    print(f"    âŒ æç«¯å€¼å¤„ç†: {params.plot_type} å¤±è´¥ - {str(e)[:50]}...")
            
            return successful >= 2  # è‡³å°‘2/3æˆåŠŸ
            
        except Exception as e:
            print(f"    âŒ æç«¯æ•°æ®æµ‹è¯•å¤±è´¥: {str(e)}")
            return False


    async def run_compatibility_tests(self):
        """è¿è¡Œå…¼å®¹æ€§æµ‹è¯•"""
        print("\nğŸ”„ è¿è¡Œå…¼å®¹æ€§æµ‹è¯•...")
        
        compatibility_results = {}
        
        # æµ‹è¯•å‘åå…¼å®¹æ€§
        compatibility_results['backward_compatibility'] = await self._test_backward_compatibility()
        
        # æµ‹è¯•ä¸åŒæ•°æ®æ ¼å¼å…¼å®¹æ€§
        compatibility_results['data_format_compatibility'] = await self._test_data_format_compatibility()
        
        # æµ‹è¯•åº“ç‰ˆæœ¬å…¼å®¹æ€§
        compatibility_results['library_compatibility'] = await self._test_library_compatibility()
        
        return compatibility_results
    
    async def _test_backward_compatibility(self):
        """æµ‹è¯•å‘åå…¼å®¹æ€§"""
        try:
            data_store = {"test": {"adata": self.data_variants['medium']}}
            
            # æµ‹è¯•æ—§å¼å‚æ•°è°ƒç”¨
            old_style_params = [
                # åªä½¿ç”¨åŸºç¡€å‚æ•°
                VisualizationParameters(plot_type="spatial"),
                VisualizationParameters(plot_type="umap"),
                VisualizationParameters(plot_type="heatmap"),
                VisualizationParameters(plot_type="violin"),
                
                # ä½¿ç”¨æ—§çš„å‚æ•°å
                VisualizationParameters(plot_type="spatial", feature="Gene_0", colormap="viridis"),
                VisualizationParameters(plot_type="umap", feature="leiden", show_legend=True)
            ]
            
            successful = 0
            
            for params in old_style_params:
                try:
                    result = await visualize_data("test", data_store, params)
                    successful += 1
                except Exception as e:
                    print(f"    âŒ å‘åå…¼å®¹æ€§å¤±è´¥: {params.plot_type} - {str(e)[:30]}...")
            
            compatibility_rate = successful / len(old_style_params)
            print(f"    ğŸ“Š å‘åå…¼å®¹æ€§: {compatibility_rate*100:.1f}% ({successful}/{len(old_style_params)})")
            
            return compatibility_rate == 1.0  # 100% å‘åå…¼å®¹
            
        except Exception as e:
            print(f"    âŒ å‘åå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_data_format_compatibility(self):
        """æµ‹è¯•ä¸åŒæ•°æ®æ ¼å¼å…¼å®¹æ€§"""
        try:
            # æµ‹è¯•ä¸åŒç±»å‹çš„æ•°æ®é›†
            test_datasets = [
                ('tiny', self.data_variants['tiny']),
                ('sparse', self.data_variants['sparse']),
                ('visium', self.data_variants['visium']),
                ('imbalanced', self.data_variants['imbalanced'])
            ]
            
            successful = 0
            
            for name, adata in test_datasets:
                try:
                    data_store = {"test": {"adata": adata}}
                    params = VisualizationParameters(plot_type="spatial", feature="Gene_0")
                    result = await visualize_data("test", data_store, params)
                    successful += 1
                    print(f"    âœ… æ•°æ®æ ¼å¼å…¼å®¹: {name}")
                except Exception as e:
                    print(f"    âŒ æ•°æ®æ ¼å¼ä¸å…¼å®¹: {name} - {str(e)[:40]}...")
            
            compatibility_rate = successful / len(test_datasets)
            print(f"    ğŸ“Š æ•°æ®æ ¼å¼å…¼å®¹æ€§: {compatibility_rate*100:.1f}%")
            
            return compatibility_rate >= 0.75  # è‡³å°‘75%å…¼å®¹
            
        except Exception as e:
            print(f"    âŒ æ•°æ®æ ¼å¼å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    async def _test_library_compatibility(self):
        """æµ‹è¯•åº“ç‰ˆæœ¬å…¼å®¹æ€§"""
        try:
            # æ£€æŸ¥å…³é”®åº“çš„å¯ç”¨æ€§
            libraries_status = {}
            
            # æµ‹è¯•scanpy
            try:
                import scanpy as sc
                libraries_status['scanpy'] = f"âœ… {sc.__version__}"
            except ImportError:
                libraries_status['scanpy'] = "âŒ ä¸å¯ç”¨"
            
            # æµ‹è¯•matplotlib
            try:
                import matplotlib
                libraries_status['matplotlib'] = f"âœ… {matplotlib.__version__}"
            except ImportError:
                libraries_status['matplotlib'] = "âŒ ä¸å¯ç”¨"
            
            # æµ‹è¯•numpy
            try:
                import numpy as np
                libraries_status['numpy'] = f"âœ… {np.__version__}"
            except ImportError:
                libraries_status['numpy'] = "âŒ ä¸å¯ç”¨"
            
            # æµ‹è¯•pandas
            try:
                import pandas as pd
                libraries_status['pandas'] = f"âœ… {pd.__version__}"
            except ImportError:
                libraries_status['pandas'] = "âŒ ä¸å¯ç”¨"
            
            # æµ‹è¯•å¯é€‰åº“
            try:
                import networkx as nx
                libraries_status['networkx'] = f"âœ… {nx.__version__}"
            except ImportError:
                libraries_status['networkx'] = "âš ï¸ å¯é€‰åº“ä¸å¯ç”¨"
            
            try:
                import scvelo
                libraries_status['scvelo'] = f"âœ… {scvelo.__version__}"
            except ImportError:
                libraries_status['scvelo'] = "âš ï¸ å¯é€‰åº“ä¸å¯ç”¨"
            
            print("    ğŸ“š åº“å…¼å®¹æ€§æ£€æŸ¥:")
            for lib, status in libraries_status.items():
                print(f"      {lib}: {status}")
            
            # è®¡ç®—å¿…éœ€åº“å¯ç”¨ç‡
            required_libs = ['scanpy', 'matplotlib', 'numpy', 'pandas']
            available_required = sum(1 for lib in required_libs if "âœ…" in libraries_status.get(lib, ""))
            
            return available_required == len(required_libs)
            
        except Exception as e:
            print(f"    âŒ åº“å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {str(e)}")
            return False


    def generate_test_report(self, all_results):
        """ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ”¬ è¶…å…¨é¢æµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        # æ€»ä½“ç»Ÿè®¡
        total_tests = 0
        passed_tests = 0
        
        print("\nğŸ“Š æµ‹è¯•ç»“æœæ¦‚è§ˆ:")
        
        for test_category, results in all_results.items():
            if isinstance(results, dict):
                category_total = len(results)
                category_passed = sum(1 for v in results.values() if v is True)
                
                total_tests += category_total
                passed_tests += category_passed
                
                success_rate = (category_passed / category_total * 100) if category_total > 0 else 0
                
                print(f"  {test_category}: {category_passed}/{category_total} ({success_rate:.1f}%)")
                
                # æ˜¾ç¤ºå¤±è´¥çš„æµ‹è¯•
                failed_tests = [k for k, v in results.items() if v is False]
                if failed_tests:
                    print(f"    âŒ å¤±è´¥: {', '.join(failed_tests)}")
        
        overall_success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"\nğŸ¯ æ€»ä½“æˆåŠŸç‡: {overall_success_rate:.1f}% ({passed_tests}/{total_tests})")
        
        # æ€§èƒ½æŠ¥å‘Š
        if hasattr(self, 'performance_results') and self.performance_results:
            print("\nâš¡ æ€§èƒ½åˆ†æ:")
            
            for dataset_name, dataset_perf in self.performance_results.items():
                print(f"  ğŸ“Š æ•°æ®é›† {dataset_name}:")
                
                for viz_type, perf_data in dataset_perf.items():
                    if perf_data.get('success'):
                        time_str = f"{perf_data['time']:.2f}s"
                        if 'time_per_cell' in perf_data:
                            time_str += f" ({perf_data['time_per_cell']:.2f}ms/cell)"
                        print(f"    âœ… {viz_type}: {time_str}")
                    else:
                        print(f"    âŒ {viz_type}: FAILED")
        
        # æ•°æ®é›†ä¿¡æ¯
        print("\nğŸ“ˆ æµ‹è¯•æ•°æ®é›†ä¿¡æ¯:")
        for name, adata in self.data_variants.items():
            print(f"  {name}: {adata.n_obs} cells, {adata.n_vars} genes")
        
        # å»ºè®®å’Œç»“è®º
        print("\nğŸ’¡ æµ‹è¯•ç»“è®ºå’Œå»ºè®®:")
        
        if overall_success_rate >= 95:
            print("  ğŸ‰ ä¼˜ç§€ï¼ç³»ç»Ÿè¡¨ç°éå¸¸ç¨³å®šï¼Œæ‰€æœ‰åŠŸèƒ½éƒ½å·¥ä½œæ­£å¸¸ã€‚")
        elif overall_success_rate >= 85:
            print("  âœ… è‰¯å¥½ï¼å¤§éƒ¨åˆ†åŠŸèƒ½æ­£å¸¸ï¼Œå°‘æ•°è¾¹ç•Œæƒ…å†µéœ€è¦æ³¨æ„ã€‚")
        elif overall_success_rate >= 70:
            print("  âš ï¸  ä¸€èˆ¬ã€‚æœ‰ä¸€äº›é—®é¢˜éœ€è¦è§£å†³ï¼Œå»ºè®®ä¼˜åŒ–é”™è¯¯å¤„ç†ã€‚")
        else:
            print("  âŒ éœ€è¦æ”¹è¿›ã€‚å­˜åœ¨è¾ƒå¤šé—®é¢˜ï¼Œéœ€è¦é‡ç‚¹ä¿®å¤ã€‚")
        
        print("\n" + "="*80)
        
        return overall_success_rate


    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¶…å…¨é¢æµ‹è¯•å¥—ä»¶")
        print("="*60)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.create_various_test_datasets()
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•ç±»åˆ«
        all_results = {}
        
        # 1. è¾¹ç•Œæƒ…å†µæµ‹è¯•
        all_results['edge_cases'] = await self.run_edge_case_tests()
        
        # 2. æ€§èƒ½æµ‹è¯•
        all_results['performance'] = await self.run_performance_tests()
        
        # 3. å‹åŠ›æµ‹è¯•
        all_results['stress_tests'] = await self.run_stress_tests()
        
        # 4. å…¼å®¹æ€§æµ‹è¯•
        all_results['compatibility'] = await self.run_compatibility_tests()
        
        # ç”ŸæˆæŠ¥å‘Š
        final_score = self.generate_test_report(all_results)
        
        return final_score, all_results


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    test_suite = ComprehensiveTestSuite()
    
    start_time = time.time()
    final_score, results = await test_suite.run_all_tests()
    end_time = time.time()
    
    print(f"\nâ±ï¸ æ€»æµ‹è¯•æ—¶é—´: {end_time - start_time:.2f}ç§’")
    print(f"ğŸ† æœ€ç»ˆè¯„åˆ†: {final_score:.1f}%")
    
    # æ ¹æ®è¯„åˆ†è¿”å›é€‚å½“çš„é€€å‡ºç 
    if final_score >= 90:
        exit_code = 0  # ä¼˜ç§€
    elif final_score >= 80:
        exit_code = 1  # è‰¯å¥½ä½†æœ‰æ”¹è¿›ç©ºé—´
    else:
        exit_code = 2  # éœ€è¦é‡å¤§æ”¹è¿›
    
    return exit_code


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)